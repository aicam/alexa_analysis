{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/alexa.com_site_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['site link', 'category',\n",
       "       'keyword_opportunities_breakdown_optimization_opportunities',\n",
       "       'keyword_opportunities_breakdown_keyword_gaps',\n",
       "       'keyword_opportunities_breakdown_easy_to_rank_keywords',\n",
       "       'keyword_opportunities_breakdown_buyer_keywords',\n",
       "       'all_topics_keyword_gaps_name_parameter_1',\n",
       "       'all_topics_keyword_gaps_name_parameter_2',\n",
       "       'all_topics_keyword_gaps_name_parameter_3',\n",
       "       'all_topics_keyword_gaps_name_parameter_4',\n",
       "       'all_topics_keyword_gaps_Avg_traffic_parameter_1',\n",
       "       'all_topics_keyword_gaps_Avg_traffic_parameter_2',\n",
       "       'all_topics_keyword_gaps_Avg_traffic_parameter_3',\n",
       "       'all_topics_keyword_gaps_Avg_traffic_parameter_4',\n",
       "       'all_topics_keyword_gaps_search_popularity_parameter_1',\n",
       "       'all_topics_keyword_gaps_search_popularity_parameter_2',\n",
       "       'all_topics_keyword_gaps_search_popularity_parameter_3',\n",
       "       'all_topics_keyword_gaps_search_popularity_parameter_4',\n",
       "       'all_topics_easy_to_rank_keywords_name_parameter_1',\n",
       "       'all_topics_easy_to_rank_keywords_name_parameter_2',\n",
       "       'all_topics_easy_to_rank_keywords_name_parameter_3',\n",
       "       'all_topics_easy_to_rank_keywords_name_parameter_4',\n",
       "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_1',\n",
       "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_2',\n",
       "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_3',\n",
       "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_4',\n",
       "       'all_topics_easy_to_rank_keywords_search_pop_parameter_1',\n",
       "       'all_topics_easy_to_rank_keywords_search_pop_parameter_2',\n",
       "       'all_topics_easy_to_rank_keywords_search_pop_parameter_3',\n",
       "       'all_topics_easy_to_rank_keywords_search_pop_parameter_4',\n",
       "       'all_topics_buyer_keywords_name_parameter_1',\n",
       "       'all_topics_buyer_keywords_name_parameter_2',\n",
       "       'all_topics_buyer_keywords_name_parameter_3',\n",
       "       'all_topics_buyer_keywords_name_parameter_4',\n",
       "       'all_topics_buyer_keywords_Avg_traffic_parameter_1',\n",
       "       'all_topics_buyer_keywords_Avg_traffic_parameter_2',\n",
       "       'all_topics_buyer_keywords_Avg_traffic_parameter_3',\n",
       "       'all_topics_buyer_keywords_Avg_traffic_parameter_4',\n",
       "       'all_topics_buyer_keywords_organic_competition_parameter_1',\n",
       "       'all_topics_buyer_keywords_organic_competition_parameter_2',\n",
       "       'all_topics_buyer_keywords_organic_competition_parameter_3',\n",
       "       'all_topics_buyer_keywords_organic_competition_parameter_4',\n",
       "       'all_topics_optimization_opportunities_name_parameter_1',\n",
       "       'all_topics_optimization_opportunities_name_parameter_2',\n",
       "       'all_topics_optimization_opportunities_name_parameter_3',\n",
       "       'all_topics_optimization_opportunities_name_parameter_4',\n",
       "       'all_topics_optimization_opportunities_search_pop_parameter_1',\n",
       "       'all_topics_optimization_opportunities_search_pop_parameter_2',\n",
       "       'all_topics_optimization_opportunities_search_pop_parameter_3',\n",
       "       'all_topics_optimization_opportunities_search_pop_parameter_4',\n",
       "       'all_topics_optimization_opportunities_organic_share_of_voice_parameter_1',\n",
       "       'all_topics_optimization_opportunities_organic_share_of_voice_parameter_2',\n",
       "       'all_topics_optimization_opportunities_organic_share_of_voice_parameter_3',\n",
       "       'all_topics_optimization_opportunities_organic_share_of_voice_parameter_4',\n",
       "       'all_topics_top_keywords_name_parameter_1',\n",
       "       'all_topics_top_keywords_name_parameter_2',\n",
       "       'all_topics_top_keywords_name_parameter_3',\n",
       "       'all_topics_top_keywords_name_parameter_4',\n",
       "       'all_topics_top_keywords_search_traffic_parameter_1',\n",
       "       'all_topics_top_keywords_search_traffic_parameter_2',\n",
       "       'all_topics_top_keywords_search_traffic_parameter_3',\n",
       "       'all_topics_top_keywords_search_traffic_parameter_4',\n",
       "       'all_topics_top_keywords_share_of_voice_parameter_1_percentage',\n",
       "       'all_topics_top_keywords_share_of_voice_parameter_2_percentage',\n",
       "       'all_topics_top_keywords_share_of_voice_parameter_3_percentage',\n",
       "       'all_topics_top_keywords_share_of_voice_parameter_4_percentage',\n",
       "       'comparison_metrics_search_traffic_this_site_percentage',\n",
       "       'comparison_metrics_search_traffic_Comp Avg_percentage',\n",
       "       'comparison_metrics_data_bounce_rate_this_site_percentage',\n",
       "       'comparison_metrics_data_bounce_rate_comp_avg_percentage',\n",
       "       'comparison_metrics_data_sites_linking_in_this_site_percentage',\n",
       "       'comparison_metrics_data_sites_linking_in_comp_avg_percentage',\n",
       "       'audience_overlap_sites_overlap_scores_parameter_1',\n",
       "       'audience_overlap_sites_overlap_scores_parameter_2',\n",
       "       'audience_overlap_sites_overlap_scores_parameter_3',\n",
       "       'audience_overlap_sites_overlap_scores_parameter_4',\n",
       "       'audience_overlap_sites_overlap_scores_parameter_5',\n",
       "       'audience_overlap_similar_sites_to_this_site_parameter_1',\n",
       "       'audience_overlap_similar_sites_to_this_site_parameter_2',\n",
       "       'audience_overlap_similar_sites_to_this_site_parameter_3',\n",
       "       'audience_overlap_similar_sites_to_this_site_parameter_4',\n",
       "       'audience_overlap_similar_sites_to_this_site_parameter_5',\n",
       "       'This_site_rank_in_global_internet_engagement', 'Daily_time_on_site'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols3 = ['all_topics_easy_to_rank_keywords_search_pop_parameter_1',\n",
    "       'all_topics_easy_to_rank_keywords_search_pop_parameter_2',\n",
    "       'all_topics_easy_to_rank_keywords_search_pop_parameter_3',\n",
    "       'all_topics_easy_to_rank_keywords_search_pop_parameter_4']\n",
    "\n",
    "cols2 = ['all_topics_easy_to_rank_keywords_relevance_to_site_parameter_1',\n",
    "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_2',\n",
    "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_3',\n",
    "       'all_topics_easy_to_rank_keywords_relevance_to_site_parameter_4',]\n",
    "\n",
    "cols4 = ['all_topics_keyword_gaps_Avg_traffic_parameter_1',\n",
    "       'all_topics_keyword_gaps_Avg_traffic_parameter_2',\n",
    "       'all_topics_keyword_gaps_Avg_traffic_parameter_3',\n",
    "       'all_topics_keyword_gaps_Avg_traffic_parameter_4']\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "cols5 = ['all_topics_keyword_gaps_search_popularity_parameter_1',\n",
    "       'all_topics_keyword_gaps_search_popularity_parameter_2',\n",
    "       'all_topics_keyword_gaps_search_popularity_parameter_3',\n",
    "       'all_topics_keyword_gaps_search_popularity_parameter_4']\n",
    "\n",
    "cols6 = ['all_topics_buyer_keywords_Avg_traffic_parameter_1',\n",
    "        'all_topics_buyer_keywords_Avg_traffic_parameter_2',\n",
    "        'all_topics_buyer_keywords_Avg_traffic_parameter_3',\n",
    "        'all_topics_buyer_keywords_Avg_traffic_parameter_4']\n",
    "\n",
    "cols7 = ['all_topics_buyer_keywords_organic_competition_parameter_1',\n",
    "        'all_topics_buyer_keywords_organic_competition_parameter_2',\n",
    "        'all_topics_buyer_keywords_organic_competition_parameter_3',\n",
    "        'all_topics_buyer_keywords_organic_competition_parameter_4']\n",
    "\n",
    "cols8 = ['all_topics_optimization_opportunities_search_pop_parameter_1',\n",
    "        'all_topics_optimization_opportunities_search_pop_parameter_2',\n",
    "        'all_topics_optimization_opportunities_search_pop_parameter_3',\n",
    "        'all_topics_optimization_opportunities_search_pop_parameter_4']\n",
    "\n",
    "cols9 = ['all_topics_optimization_opportunities_organic_share_of_voice_parameter_1',\n",
    "        'all_topics_optimization_opportunities_organic_share_of_voice_parameter_2',\n",
    "        'all_topics_optimization_opportunities_organic_share_of_voice_parameter_3',\n",
    "        'all_topics_optimization_opportunities_organic_share_of_voice_parameter_4']\n",
    "\n",
    "cols10 = ['all_topics_top_keywords_search_traffic_parameter_1',\n",
    "         'all_topics_top_keywords_search_traffic_parameter_2',\n",
    "         'all_topics_top_keywords_search_traffic_parameter_3',\n",
    "         'all_topics_top_keywords_search_traffic_parameter_4']\n",
    "\n",
    "cols11 = ['all_topics_top_keywords_share_of_voice_parameter_1_percentage',\n",
    "         'all_topics_top_keywords_share_of_voice_parameter_2_percentage',\n",
    "         'all_topics_top_keywords_share_of_voice_parameter_3_percentage',\n",
    "         'all_topics_top_keywords_share_of_voice_parameter_4_percentage']\n",
    "\n",
    "cols12 = ['audience_overlap_sites_overlap_scores_parameter_1',\n",
    "         'audience_overlap_sites_overlap_scores_parameter_2',\n",
    "         'audience_overlap_sites_overlap_scores_parameter_3',\n",
    "         'audience_overlap_sites_overlap_scores_parameter_4',\n",
    "         'audience_overlap_sites_overlap_scores_parameter_5']\n",
    "\n",
    "cols13 = ['audience_overlap_similar_sites_to_this_site_parameter_1',\n",
    "         'audience_overlap_similar_sites_to_this_site_parameter_2',\n",
    "         'audience_overlap_similar_sites_to_this_site_parameter_3',\n",
    "         'audience_overlap_similar_sites_to_this_site_parameter_4',\n",
    "         'audience_overlap_similar_sites_to_this_site_parameter_5']\n",
    "\n",
    "df.loc[:,'all_topics_easy_to_rank_relevance_to_site_average'] = df.loc[:, cols2].mean(axis=1)\n",
    "df.loc[:,'all_topics_easy_to_rank_keywords_search_pop_average'] = df.loc[:, cols3].mean(axis=1)\n",
    "df.loc[:,'all_topics_keyword_gaps_Avg_traffic_average'] = df.loc[:, cols4].mean(axis=1)\n",
    "df.loc[:,'all_topics_keyword_gaps_search_popularity_average'] = df.loc[:, cols5].mean(axis=1)\n",
    "\n",
    "df.loc[:,'all_topics_buyer_keywords_Avg_traffic_average'] = df.loc[:, cols6].mean(axis=1)\n",
    "df.loc[:,'all_topics_buyer_keywords_organic_competition_average'] = df.loc[:, cols7].mean(axis=1)\n",
    "df.loc[:,'all_topics_optimization_opportunities_search_pop_average'] = df.loc[:, cols8].mean(axis=1)\n",
    "df.loc[:,'all_topics_optimization_opportunities_organic_share_of_voice_average'] = df.loc[:, cols9].mean(axis=1)\n",
    "df.loc[:,'all_topics_top_keywords_search_traffic_average'] = df.loc[:, cols10].mean(axis=1)\n",
    "df.loc[:,'all_topics_top_keywords_share_of_voice_average'] = df.loc[:, cols11].mean(axis=1)\n",
    "df.loc[:,'audience_overlap_sites_overlap_scores_average'] = df.loc[:, cols12].mean(axis=1)\n",
    "df.loc[:,'audience_overlap_similar_sites_to_this_site_average'] = df.loc[:, cols13].mean(axis=1)\n",
    "\n",
    "# Ali ! sotoon haye zir ro ham too clustring et estefade kon ina taki an o dige parameter i nadaran o average barashoon maani nadare\n",
    "# 'comparison_metrics_search_traffic_this_site_percentage'\n",
    "# 'comparison_metrics_search_traffic_Comp Avg_percentage'\n",
    "# 'comparison_metrics_data_bounce_rate_this_site_percentage'\n",
    "# 'comparison_metrics_data_bounce_rate_comp_avg_percentage'\n",
    "# 'comparison_metrics_data_sites_linking_in_this_site_percentage'\n",
    "# 'comparison_metrics_data_sites_linking_in_comp_avg_percentage'\n",
    "# 'This_site_rank_in_global_internet_engagement'\n",
    "# 'Daily_time_on_site'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'comparison_metrics_search_traffic_this_site_percentage': 'comparison_metrics_search_traffic_this_site_percentage_average'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    input_img = Input(shape=(dims[0],), name='input')\n",
    "    x = input_img\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
    "\n",
    "    # hidden layer\n",
    "    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n",
    "\n",
    "    x = encoded\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
    "\n",
    "    # output\n",
    "    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
    "    decoded = x\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = re.compile('.*_average')\n",
    "x = df[[s for s in df.columns if p.match(s)]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.delete(x, 11, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 1, ..., 2, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clusters = 10\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20, n_jobs=4)\n",
    "y_pred_kmeans = kmeans.fit_predict(x)\n",
    "ny_pred_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8829/8829 [==============================] - 0s 48us/step - loss: 3602313550634504065011154944.0000\n",
      "Epoch 2/20\n",
      "8829/8829 [==============================] - 0s 33us/step - loss: 136786788941554.7969\n",
      "Epoch 3/20\n",
      "8829/8829 [==============================] - 0s 34us/step - loss: 181.2131\n",
      "Epoch 4/20\n",
      "8829/8829 [==============================] - 0s 33us/step - loss: 135.6744\n",
      "Epoch 5/20\n",
      "8829/8829 [==============================] - 0s 33us/step - loss: 135.7239\n",
      "Epoch 6/20\n",
      "8829/8829 [==============================] - 0s 36us/step - loss: 135.7020\n",
      "Epoch 7/20\n",
      "8829/8829 [==============================] - 0s 33us/step - loss: 135.7393\n",
      "Epoch 8/20\n",
      "8829/8829 [==============================] - 0s 33us/step - loss: 135.6911\n",
      "Epoch 9/20\n",
      "8829/8829 [==============================] - 0s 34us/step - loss: 135.7413\n",
      "Epoch 10/20\n",
      "8829/8829 [==============================] - 0s 34us/step - loss: 135.7770\n",
      "Epoch 11/20\n",
      "8829/8829 [==============================] - 0s 36us/step - loss: 135.6509\n",
      "Epoch 12/20\n",
      "8829/8829 [==============================] - 0s 36us/step - loss: 135.7869\n",
      "Epoch 13/20\n",
      "8829/8829 [==============================] - 0s 32us/step - loss: 135.5547\n",
      "Epoch 14/20\n",
      "8829/8829 [==============================] - 0s 34us/step - loss: 135.7420\n",
      "Epoch 15/20\n",
      "8829/8829 [==============================] - 0s 39us/step - loss: 135.7287\n",
      "Epoch 16/20\n",
      "8829/8829 [==============================] - 0s 33us/step - loss: 135.6562\n",
      "Epoch 17/20\n",
      "8829/8829 [==============================] - 0s 35us/step - loss: 135.6988\n",
      "Epoch 18/20\n",
      "8829/8829 [==============================] - 0s 35us/step - loss: 135.7443\n",
      "Epoch 19/20\n",
      "8829/8829 [==============================] - 0s 36us/step - loss: 135.7009\n",
      "Epoch 20/20\n",
      "8829/8829 [==============================] - 0s 35us/step - loss: 135.6656\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add_weight() got multiple values for argument 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-e58e1ced49aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0mclustering_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusteringLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clustering'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclustering_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kld'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 463\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-e58e1ced49aa>\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0minput_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clusters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_weights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: add_weight() got multiple values for argument 'name'"
     ]
    }
   ],
   "source": [
    "clus_cent=kmeans.cluster_centers_\n",
    "clus_cent\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import keras.backend as K\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras import callbacks\n",
    "from keras.initializers import VarianceScaling\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    input_img = Input(shape=(dims[0],), name='input')\n",
    "    x = input_img\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        x = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(x)\n",
    "\n",
    "    # hidden layer\n",
    "    encoded = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(x)  # hidden layer, features are extracted from here\n",
    "\n",
    "    x = encoded\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        x = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(x)\n",
    "\n",
    "    # output\n",
    "    x = Dense(dims[0], kernel_initializer=init, name='decoder_0')(x)\n",
    "    decoded = x\n",
    "    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')\n",
    "\n",
    "n_clusters = 11\n",
    "kmeans = KMeans(n_clusters=n_clusters, n_init=20, n_jobs=4)\n",
    "y_pred_kmeans = kmeans.fit_predict(x)\n",
    "y_pred_kmeans[:10]\n",
    "\n",
    "\n",
    "# 10 means the 10 MINST classification\n",
    "dims = [11, 10, 8, 7]\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',\n",
    "                           distribution='uniform')\n",
    "pretrain_optimizer = SGD(lr=0.1, momentum=0.9)\n",
    "\n",
    "# dims represents the dense layer units number : 5 layers have each unit cell number\n",
    "autoencoder, encoder = autoencoder(dims, init=init)\n",
    "autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n",
    "autoencoder.fit(x, x, epochs=20) #, callbacks=cb)\n",
    "# autoencoder.save_weights(save_dir + '/ae_weights.h5')\n",
    "class ClusteringLayer(Layer):\n",
    "    \n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "    \n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) # Make sure each sample's 10 values add up to 1.\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=encoder.input, outputs=clustering_layer)\n",
    "model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "encoder.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
